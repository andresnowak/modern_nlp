{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews = pd.read_csv('data/IMDB Dataset.csv')\n",
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movie reviews: 50000\n",
      "Number of classes: 2 with values: ['positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "print('Number of movie reviews: {}'.format(len(movie_reviews)))\n",
    "classes = movie_reviews['sentiment'].unique()\n",
    "print('Number of classes: {} with values: {}'.format(len(classes), classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = movie_reviews.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_corpus = [list(gensim.utils.tokenize(movie_reviews[\"review\"][i])) for i in range(len(movie_reviews))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for i in review_corpus:\n",
    "    for j in i:\n",
    "        vocab.add(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(set(vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14153"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one hot encoding embeddings\n",
    "\n",
    "vocab = np.array(list(vocab)).reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, dtype=np.float32)\n",
    "one_hot_vocab = encoder.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict the word based on the context $p(x_t|x_t-2, x_t-1, x_t+1, x_t+2)$ (conditional probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot_encoded_windows(sentences, word2idx, one_hot_vocab, windows_size=2):\n",
    "    window_context = []\n",
    "    window_target = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for i in range(windows_size, len(sentence) - windows_size):\n",
    "            target_word = sentence[i]\n",
    "            target_word_one_hot = one_hot_vocab[word2idx[target_word]]\n",
    "\n",
    "            prefix = sentence[i - windows_size:i]\n",
    "            suffix = sentence[i + 1: i + windows_size + 1]\n",
    "\n",
    "            prefix_one_hot = [one_hot_vocab[word2idx[word]] for word in prefix]\n",
    "            suffix_one_hot = [one_hot_vocab[word2idx[word]] for word in suffix]\n",
    "\n",
    "            context = np.zeros((2 * windows_size, VOCAB_SIZE), dtype=np.float32)\n",
    "            context[:windows_size, :] = prefix_one_hot\n",
    "            context[windows_size:2 * windows_size, :] = suffix_one_hot\n",
    "\n",
    "            window_context.append(context)\n",
    "            window_target.append(target_word_one_hot)\n",
    "\n",
    "    return window_context, window_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_context, review_target = convert_to_one_hot_encoded_windows(review_corpus, word2idx, one_hot_vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, review_context, review_target):\n",
    "        super(ReviewDataset, self).__init__()\n",
    "\n",
    "        self.context = review_context\n",
    "        self.targets = review_target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.context)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return np.array(self.context[index]), self.targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dataset = ReviewDataset(review_context, review_target)\n",
    "train_dataset, test_dataset = random_split(review_dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings are of size $d\\times 1$ and U (projection) is of size $V\\times d$ (V vocabulary size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, d_size):\n",
    "        super(CBOW, self).__init__()\n",
    "\n",
    "        self.W = torch.nn.Linear(vocab_size, d_size) # This can also be a linear layer but the embedding saves us the work by storring the embeddings and we can get them back using indices\n",
    "        # self.W = torch.nn.Embeddings(vocab_size, d_size)\n",
    "        self.U = torch.nn.Linear(d_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.W(x) # project one hot encoding vectors to their embeddings\n",
    "        x = x.sum(axis=1) # sum the embeddings\n",
    "        x = self.U(x) # project to the Vocab space (the output embedding)\n",
    "\n",
    "        # Because we want to predict the output with a softmax (from all the embeddings what should be the output)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_size = 100\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(VOCAB_SIZE, d_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "criterion_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "5.917309471784927\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "4.20934189711343\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "3.296223952075628\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "2.590538275719002\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "2.042055295286529\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "1.6208985336809334\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "1.3041989051411784\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "1.0773685624202092\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "0.9143747106644269\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "0.798372329200503\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "0.7127592436323954\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "0.6437339831700944\n",
      "0/3048\n",
      "1000/3048\n",
      "2000/3048\n",
      "3000/3048\n",
      "0.589933202100864\n",
      "0/3048\n",
      "1000/3048\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print(f\"{idx}/{len(train_dataloader)}\")\n",
    "\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = criterion_loss(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(total_loss / len(train_dataloader))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
